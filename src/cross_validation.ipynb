{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load solution.py\n",
    "# Import important libraries\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from itertools import chain\n",
    "from itertools import repeat\n",
    "from collections import OrderedDict\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "config = {}\n",
    "\n",
    "# E.g. \"1.256660 0.431805 -4.981400\"\n",
    "def parse_coords(text):\n",
    "    return [float(x) for x in text.split(' ')]\n",
    "\n",
    "def iter_dataset(xml_tree):\n",
    "    for child in xml_tree.getroot():\n",
    "        name = int(child.tag.split('_')[1])\n",
    "        try:\n",
    "            energy =  float(child.find('energy').text)\n",
    "        except AttributeError:\n",
    "            energy = np.nan\n",
    "        atoms = [parse_coords(element.text) for element in child.find('coordinates').findall('c')]\n",
    "        for i, coords in enumerate(atoms):\n",
    "            yield {'Entry':name, 'Energy':energy, 'Atom': i, 'X':coords[0], 'Y':coords[1], 'Z':coords[2]}\n",
    "\n",
    "def parse_dataset(xml_file):\n",
    "    xml_tree = ET.parse(xml_file)\n",
    "    training_set = list(iter_dataset(xml_tree))\n",
    "\n",
    "    return pd.DataFrame(training_set, columns=('Entry', 'Energy', 'Atom', 'X', 'Y', 'Z'))\n",
    "    \n",
    "def get_pos(data, entry):\n",
    "    # Convert the X, Y, Z position for entry to a numpy array of size 60x3\n",
    "    \n",
    "    # Get single entry\n",
    "    E = data[data['Entry'] == entry]\n",
    "    if E.empty:\n",
    "        print('Invalid Entry id!')\n",
    "        return None\n",
    "    \n",
    "    # Get the position in format Nx3\n",
    "    E_ = E.apply(lambda row: [row['X'], row['Y'], row['Z']], axis=1).values\n",
    "    \n",
    "    # Transform it to a numpy array\n",
    "    Epos = np.reshape(list(chain(*E_)), (60, 3))\n",
    "    \n",
    "    return Epos\n",
    "\n",
    "\n",
    "def get_distance(pos0, pos1, method='atom_pos'):\n",
    "    # Calculate a distance value between e0 and e1 based on\n",
    "    # method='atom_pos' ... their cummulative difference in atom positions\n",
    "    # method='mesh_size' ... the abs. diff in mean atom gap size (i.e mesh size)\n",
    "    # method='mesh_size_variance' ... the abs. diff of variance of the mean atom gap size (i.e variance of the mesh size)\n",
    "    \n",
    "    if method == 'atom_pos':\n",
    "        # Calculate the distance matrix\n",
    "        D = cdist(pos0, pos1, metric='euclidean')\n",
    "\n",
    "        # Find the closest match for each point\n",
    "        assignment = np.argsort(D, axis=1)[:, 0]\n",
    "\n",
    "        # Calculate distance between each point to its assigned point\n",
    "        distance = np.sum(np.sqrt(np.sum((pos0 - pos1[assignment, :])**2, axis=1)))\n",
    "        \n",
    "    elif method == 'mesh_size':\n",
    "        # For each atom calculate the mean distance to its three closest neighbours\n",
    "        D0 = cdist(pos0, pos0, metric='euclidean')\n",
    "        D0.sort(axis=1)\n",
    "        D0_mesh_size = np.mean(D0[:, 1:4])\n",
    "\n",
    "        D1 = cdist(pos1, pos1, metric='euclidean')\n",
    "        D1.sort(axis=1)\n",
    "        D1_mesh_size = np.mean(D1[:, 1:4])\n",
    "        \n",
    "        distance = np.abs(D0_mesh_size - D1_mesh_size)\n",
    "\n",
    "    elif method == 'mesh_size_variance':\n",
    "        # For each atom calculate the mean distance to its three closest neighbours\n",
    "        D0 = cdist(pos0, pos0, metric='euclidean')\n",
    "        D0.sort(axis=1)\n",
    "        D0_mesh_size_var = np.var(np.mean(D0[:, 1:4], axis=1))\n",
    "\n",
    "        D1 = cdist(pos1, pos1, metric='euclidean')\n",
    "        D1.sort(axis=1)\n",
    "        D1_mesh_size_var = np.var(np.mean(D1[:, 1:4], axis=1))\n",
    "        \n",
    "        distance = np.abs(D0_mesh_size_var - D1_mesh_size_var)\n",
    "       \n",
    "    return distance\n",
    "\n",
    "\n",
    "def calculate_ranking(prediction_data, lookup_data, distance_method = ''):\n",
    "    # For each entry in 'prediction_data' rank all entries in 'data'\n",
    "    #\n",
    "    # Return a ordered Dictionary containg for each prediction_data Entry\n",
    "    # a tuple describing the similary/distance to each entry in the lookup table.\n",
    "    \n",
    "    prediction_entries = prediction_data['Entry'].drop_duplicates()\n",
    "    lookup_entries = lookup_data['Entry'].drop_duplicates()\n",
    "    \n",
    "    results = OrderedDict()\n",
    "    for pre in prediction_entries:\n",
    "        ranking = []\n",
    "        e0pos = get_pos(prediction_data, pre)\n",
    "        for (e0, e1) in zip(repeat(pre), lookup_entries):\n",
    "            e1pos = get_pos(lookup_data, e1)\n",
    "            d = get_distance(e1pos, e0pos, method=distance_method)\n",
    "            ranking.append((d, e1))\n",
    "\n",
    "        ranking.sort()\n",
    "        results[pre] = ranking\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results, lookup_data):\n",
    "    # Based on the ranking calculate a energy value for each entry by\n",
    "    # taking the mean energy value of its 3 closest matches.\n",
    "\n",
    "    entries = []\n",
    "    predictions = []\n",
    "    for entry_id in results.keys():\n",
    "        entries.append(entry_id)\n",
    "        closest_entries = [res[1] for res in results[entry_id][0:3]]\n",
    "        predictions.append(np.mean(get_energies(lookup_data, closest_entries)))\n",
    "    \n",
    "    return entries, predictions\n",
    "\n",
    "\n",
    "def single_stage_prediction(training, validation):\n",
    "    ranking = calculate_ranking(validation, training, distance_method='atom_pos')   \n",
    "    entries, predictions = get_predictions(ranking, training)\n",
    "    return entries, predictions\n",
    "\n",
    "\n",
    "def two_stage_prediction(training, validation, energy_sw=0.1):\n",
    "    ranking = calculate_ranking(validation, training, distance_method='atom_pos')   \n",
    "    entries, predictions = get_predictions(ranking, training)\n",
    "\n",
    "    # For each entry in the first prediction generate a subset of the training data\n",
    "    # and apply another distance metric to the subset in order to calculate\n",
    "    # a improved prediction\n",
    "    new_predictions = []\n",
    "    for entry_id, predicted_energy in zip(entries, predictions):\n",
    "        # Calculate a subset of the data\n",
    "        training_subset = training[(training['Energy'] > (predicted_energy-energy_sw)) & (training['Energy'] < (predicted_energy+energy_sw))]\n",
    "        validation_subset = validation[validation['Entry'] == entry_id]\n",
    "\n",
    "        new_ranking = calculate_ranking(validation_subset, training_subset, distance_method='mesh_size_variance')   \n",
    "        _, new_prediction = get_predictions(new_ranking, training_subset)\n",
    "    \n",
    "        new_predictions.append(new_prediction[0])\n",
    "    \n",
    "    return entries, new_predictions\n",
    "\n",
    "\n",
    "############### HELPER FUNCTIONS - NOT PART OF THE ALGORITHM ###############\n",
    "\n",
    "def evaluate_prediction(entry_ids, predicted_energies, lookup_table):\n",
    "    # Calculate the prediction error\n",
    "    prediction_errors = []\n",
    "    for entry_id, predicted_energy in zip(entry_ids, predicted_energies):\n",
    "        real_energy = lookup_table[lookup_table['Entry'] == entry_id]['Energy'].values[0]\n",
    "        prediction_errors.append(predicted_energy - real_energy)\n",
    "        \n",
    "    return np.array(prediction_errors)\n",
    "\n",
    "\n",
    "def cross_validation(n_tests, n_entries, training_data, prediction_function, kwargs={}):\n",
    "    prediction_errors = np.zeros(shape=(n_tests, n_entries))    \n",
    "    for n in range(0, n_tests):\n",
    "        # Split the training data into a new set of training and validation data in order to test the algorithm\n",
    "        validation_entries = set(np.random.choice(training_data['Entry'].unique(), n_entries, replace=False))\n",
    "        training_entries = set(training_data['Entry'].unique()) - validation_entries\n",
    "        \n",
    "        print('Running Test (%d/%d) with validation entries %s ...' % (n+1, n_tests, validation_entries))\n",
    "        \n",
    "        training = training_data[training_data['Entry'].isin(training_entries)]\n",
    "        validation = training_data[training_data['Entry'].isin(validation_entries)]\n",
    "\n",
    "        entries, predictions = prediction_function(training, validation, **kwargs)\n",
    "        \n",
    "        prediction_errors[n, :] = evaluate_prediction(entries, predictions, training_data)\n",
    "    \n",
    "    return prediction_errors\n",
    "\n",
    "\n",
    "def get_energies(table, entries):\n",
    "    return [table[table['Entry'] == entry]['Energy'].values[0] for entry in entries]\n",
    "        \n",
    "def get_closest_entries(table, energy):\n",
    "    uT = table[['Entry', 'Energy']].drop_duplicates()    \n",
    "    energies = uT['Energy'].values\n",
    "    entries = uT['Entry'].values    \n",
    "        \n",
    "    diff_energies = (energies - energy)**2\n",
    "    closest_energies = np.argsort(diff_energies)\n",
    "    closest_entries = entries[closest_energies]\n",
    "    \n",
    "    return closest_entries, energies[closest_energies]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data ...')\n",
    "\n",
    "# Real data   \n",
    "training_data = parse_dataset('data/new_training_set.xml')\n",
    "#validation = parse_dataset('data/new_validation_set.xml')\n",
    "\n",
    "n_entries = 5\n",
    "validation_entries = set(np.random.choice(training_data['Entry'].unique(), n_entries, replace=False))\n",
    "training_entries = set(training_data['Entry'].unique()) - validation_entries\n",
    "\n",
    "training = training_data[training_data['Entry'].isin(training_entries)]\n",
    "validation = training_data[training_data['Entry'].isin(validation_entries)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First stage lookup and prediction (traditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranking = calculate_ranking(validation, training, distance_method='atom_pos')   \n",
    "entries, predictions = get_predictions(ranking, training)\n",
    "\n",
    "new_predictions = []\n",
    "for entry_id, predicted_energy in zip(entries, predictions):\n",
    "    # Calculate a subset of the data\n",
    "    training_subset = training[(training['Energy'] > (predicted_energy-0.1)) & (training['Energy'] < (predicted_energy+0.1))]\n",
    "    validation_subset = validation[validation['Entry'] == entry_id]\n",
    "\n",
    "    new_ranking = calculate_ranking(validation_subset, training_subset, distance_method='mesh_size')   \n",
    "    _, new_prediction = get_predictions(new_ranking, training_subset)\n",
    "    \n",
    "    new_predictions.append(new_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranking = calculate_ranking(validation, training, distance_method='atom_pos')   \n",
    "entries, predictions = get_predictions(ranking, training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 17, 71, 148, 199],\n",
       " [-0.22383333333333333,\n",
       "  -0.061199999999999997,\n",
       "  -0.07173333333333333,\n",
       "  0.0041999999999999997,\n",
       "  -0.088166666666666671])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries, new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validate two stage prediction ...\n",
      "Running Test (1/10) with validation entries {144, 70, 173, 46, 89} ...\n",
      "Running Test (2/10) with validation entries {89, 203, 148, 142, 33} ...\n",
      "Running Test (3/10) with validation entries {200, 41, 130, 46, 87} ...\n",
      "Running Test (4/10) with validation entries {65, 94, 5, 133, 174} ...\n",
      "Running Test (5/10) with validation entries {180, 3, 131, 182, 15} ...\n",
      "Running Test (6/10) with validation entries {0, 113, 218, 51, 152} ...\n",
      "Running Test (7/10) with validation entries {128, 113, 88, 38, 103} ...\n",
      "Running Test (8/10) with validation entries {128, 48, 31, 54, 47} ...\n",
      "Running Test (9/10) with validation entries {129, 30, 69, 133, 15} ...\n",
      "Running Test (10/10) with validation entries {216, 139, 76, 102, 135} ...\n",
      "Mean prediction error 0.013, Var 0.012, abs.sum 4.022\n"
     ]
    }
   ],
   "source": [
    "print('Cross validate two stage prediction ...')\n",
    "training = parse_dataset('data/new_training_set.xml')\n",
    "cum_errors = cross_validation(10, 5, training, prediction_function=two_stage_prediction, kwargs={'energy_sw': 0.05})\n",
    "print('Mean prediction error %3.3f, Var %3.3f, abs.sum %3.3f' % (cum_errors.mean(), cum_errors.var(), np.sum(np.abs(cum_errors))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validate two stage prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validate single stage prediction ...\n",
      "Running Test (1/50) with validation entries {54, 171, 116, 86, 103} ...\n",
      "Running Test (2/50) with validation entries {96, 1, 45, 71, 63} ...\n",
      "Running Test (3/50) with validation entries {120, 59, 123, 140, 183} ...\n",
      "Running Test (4/50) with validation entries {129, 164, 27, 92, 85} ...\n",
      "Running Test (5/50) with validation entries {88, 151, 138, 156, 31} ...\n",
      "Running Test (6/50) with validation entries {113, 194, 12, 122, 183} ...\n",
      "Running Test (7/50) with validation entries {57, 18, 91, 54, 14} ...\n",
      "Running Test (8/50) with validation entries {48, 57, 147, 209, 155} ...\n",
      "Running Test (9/50) with validation entries {19, 57, 122, 67, 119} ...\n",
      "Running Test (10/50) with validation entries {26, 78, 34, 83, 118} ...\n",
      "Running Test (11/50) with validation entries {130, 35, 124, 21, 207} ...\n",
      "Running Test (12/50) with validation entries {43, 83, 27, 60, 29} ...\n",
      "Running Test (13/50) with validation entries {120, 113, 163, 21, 166} ...\n",
      "Running Test (14/50) with validation entries {57, 26, 107, 76, 143} ...\n",
      "Running Test (15/50) with validation entries {72, 164, 182, 62, 95} ...\n",
      "Running Test (16/50) with validation entries {64, 82, 52, 54, 130} ...\n",
      "Running Test (17/50) with validation entries {88, 46, 212, 174, 62} ...\n",
      "Running Test (18/50) with validation entries {66, 131, 196, 173, 103} ...\n",
      "Running Test (19/50) with validation entries {73, 211, 84, 173, 55} ...\n",
      "Running Test (20/50) with validation entries {114, 204, 5, 118, 183} ...\n",
      "Running Test (21/50) with validation entries {208, 217, 4, 174, 110} ...\n",
      "Running Test (22/50) with validation entries {73, 82, 123, 155, 14} ...\n",
      "Running Test (23/50) with validation entries {197, 83, 163, 124, 29} ...\n",
      "Running Test (24/50) with validation entries {128, 100, 50, 156, 182} ...\n",
      "Running Test (25/50) with validation entries {178, 57, 154, 54, 7} ...\n",
      "Running Test (26/50) with validation entries {186, 201, 162, 164, 71} ...\n",
      "Running Test (27/50) with validation entries {64, 129, 114, 213, 39} ...\n",
      "Running Test (28/50) with validation entries {72, 210, 45, 104, 77} ...\n",
      "Running Test (29/50) with validation entries {120, 57, 214, 71, 167} ...\n",
      "Running Test (30/50) with validation entries {170, 193, 10, 158, 215} ...\n",
      "Running Test (31/50) with validation entries {152, 140, 204, 12, 21} ...\n",
      "Running Test (32/50) with validation entries {216, 109, 203, 60, 77} ...\n",
      "Running Test (33/50) with validation entries {25, 194, 115, 109, 175} ...\n",
      "Running Test (34/50) with validation entries {81, 33, 187, 29, 39} ...\n",
      "Running Test (35/50) with validation entries {112, 193, 196, 212, 14} ...\n",
      "Running Test (36/50) with validation entries {128, 103, 149, 54, 135} ...\n",
      "Running Test (37/50) with validation entries {216, 207, 11, 85, 47} ...\n",
      "Running Test (38/50) with validation entries {85, 188, 164, 149, 47} ...\n",
      "Running Test (39/50) with validation entries {207, 35, 147, 52, 143} ...\n",
      "Running Test (40/50) with validation entries {136, 153, 108, 158, 76} ...\n",
      "Running Test (41/50) with validation entries {112, 153, 34, 93, 46} ...\n",
      "Running Test (42/50) with validation entries {24, 113, 180, 53, 150} ...\n",
      "Running Test (43/50) with validation entries {200, 97, 56, 94, 143} ...\n",
      "Running Test (44/50) with validation entries {192, 130, 204, 124, 159} ...\n",
      "Running Test (45/50) with validation entries {129, 154, 164, 5, 95} ...\n",
      "Running Test (46/50) with validation entries {186, 103, 85, 94, 127} ...\n",
      "Running Test (47/50) with validation entries {216, 145, 18, 19, 100} ...\n",
      "Running Test (48/50) with validation entries {9, 218, 108, 190, 158} ...\n",
      "Running Test (49/50) with validation entries {32, 161, 11, 190, 216} ...\n",
      "Running Test (50/50) with validation entries {41, 19, 25, 14, 87} ...\n",
      "Mean prediction error 0.049, Var 0.017, abs.sum 26.785\n"
     ]
    }
   ],
   "source": [
    "print('Cross validate single stage prediction ...')\n",
    "training = parse_dataset('data/new_training_set.xml')\n",
    "cum_errors = cross_validation(50, 5, training, prediction_function=single_stage_prediction)\n",
    "print('Mean prediction error %3.3f, Var %3.3f, abs.sum %3.3f' % (cum_errors.mean(), cum_errors.var(), np.sum(np.abs(cum_errors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validate two stage prediction ...\n",
      "Running Test (1/50) with validation entries {64, 80, 20, 197, 118} ...\n",
      "Running Test (2/50) with validation entries {88, 73, 45, 97, 160} ...\n",
      "Running Test (3/50) with validation entries {56, 194, 42, 123, 159} ...\n",
      "Running Test (4/50) with validation entries {128, 105, 43, 174, 183} ...\n",
      "Running Test (5/50) with validation entries {136, 82, 91, 112, 95} ...\n",
      "Running Test (6/50) with validation entries {153, 154, 164, 4, 215} ...\n",
      "Running Test (7/50) with validation entries {135, 193, 156, 104, 199} ...\n",
      "Running Test (8/50) with validation entries {24, 217, 133, 22, 183} ...\n",
      "Running Test (9/50) with validation entries {72, 81, 43, 179, 17} ...\n",
      "Running Test (10/50) with validation entries {144, 50, 115, 179, 214} ...\n",
      "Running Test (11/50) with validation entries {8, 129, 218, 204, 4} ...\n",
      "Running Test (12/50) with validation entries {217, 114, 203, 93, 215} ...\n",
      "Running Test (13/50) with validation entries {0, 162, 107, 94, 119} ...\n",
      "Running Test (14/50) with validation entries {152, 56, 91, 78, 215} ...\n",
      "Running Test (15/50) with validation entries {59, 194, 66, 85, 45} ...\n",
      "Running Test (16/50) with validation entries {143, 80, 103, 60, 159} ...\n",
      "Running Test (17/50) with validation entries {115, 17, 35, 173, 78} ...\n",
      "Running Test (18/50) with validation entries {136, 20, 144, 70, 79} ...\n",
      "Running Test (19/50) with validation entries {210, 122, 12, 82, 94} ...\n",
      "Running Test (20/50) with validation entries {160, 195, 196, 174, 52} ...\n",
      "Running Test (21/50) with validation entries {193, 123, 36, 206, 78} ...\n",
      "Running Test (22/50) with validation entries {32, 211, 164, 5, 22} ...\n",
      "Running Test (23/50) with validation entries {160, 10, 64, 63, 138} ...\n",
      "Running Test (24/50) with validation entries {57, 217, 63, 110, 159} ...\n",
      "Running Test (25/50) with validation entries {8, 105, 138, 120, 47} ...\n",
      "Running Test (26/50) with validation entries {99, 33, 91, 51, 77} ...\n",
      "Running Test (27/50) with validation entries {208, 67, 47, 182, 143} ...\n",
      "Running Test (28/50) with validation entries {32, 118, 212, 100, 54} ...\n",
      "Running Test (29/50) with validation entries {96, 137, 139, 45, 79} ...\n",
      "Running Test (30/50) with validation entries {200, 41, 83, 101, 62} ...\n",
      "Running Test (31/50) with validation entries {0, 108, 192, 110, 175} ...\n",
      "Running Test (32/50) with validation entries {107, 196, 163, 188, 94} ...\n",
      "Running Test (33/50) with validation entries {186, 37, 138, 13, 7} ...\n",
      "Running Test (34/50) with validation entries {147, 11, 76, 213, 87} ...\n",
      "Running Test (35/50) with validation entries {80, 1, 52, 133, 165} ...\n",
      "Running Test (36/50) with validation entries {32, 105, 114, 123, 117} ...\n",
      "Running Test (37/50) with validation entries {217, 172, 20, 121, 167} ...\n",
      "Running Test (38/50) with validation entries {80, 72, 114, 27, 86} ...\n",
      "Running Test (39/50) with validation entries {183, 146, 20, 206, 143} ...\n",
      "Running Test (40/50) with validation entries {114, 103, 4, 149, 175} ...\n",
      "Running Test (41/50) with validation entries {104, 97, 128, 17, 208} ...\n",
      "Running Test (42/50) with validation entries {153, 34, 177, 155, 31} ...\n",
      "Running Test (43/50) with validation entries {209, 98, 35, 84, 187} ...\n",
      "Running Test (44/50) with validation entries {124, 137, 18, 196, 199} ...\n",
      "Running Test (45/50) with validation entries {185, 162, 109, 86, 55} ...\n",
      "Running Test (46/50) with validation entries {24, 89, 120, 60, 37} ...\n",
      "Running Test (47/50) with validation entries {80, 116, 4, 87, 79} ...\n",
      "Running Test (48/50) with validation entries {116, 213, 60, 4, 22} ...\n",
      "Running Test (49/50) with validation entries {72, 138, 215, 189, 39} ...\n",
      "Running Test (50/50) with validation entries {80, 165, 13, 71, 181} ...\n",
      "Mean prediction error 0.047, Var 0.018, abs.sum 24.982\n"
     ]
    }
   ],
   "source": [
    "print('Cross validate two stage prediction ...')\n",
    "training = parse_dataset('data/new_training_set.xml')\n",
    "cum_errors = cross_validation(50, 5, training, prediction_function=two_stage_prediction, kwargs={'energy_sw': 0.1})\n",
    "print('Mean prediction error %3.3f, Var %3.3f, abs.sum %3.3f' % (cum_errors.mean(), cum_errors.var(), np.sum(np.abs(cum_errors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validate two stage prediction ...\n",
      "Running Test (1/50) with validation entries {73, 177, 147, 214, 30} ...\n",
      "Running Test (2/50) with validation entries {112, 211, 125, 87, 111} ...\n",
      "Running Test (3/50) with validation entries {152, 100, 147, 4, 103} ...\n",
      "Running Test (4/50) with validation entries {209, 203, 97, 14, 159} ...\n",
      "Running Test (5/50) with validation entries {137, 154, 41, 118, 207} ...\n",
      "Running Test (6/50) with validation entries {89, 19, 36, 46, 127} ...\n",
      "Running Test (7/50) with validation entries {116, 162, 11, 20, 102} ...\n",
      "Running Test (8/50) with validation entries {113, 218, 147, 193, 154} ...\n",
      "Running Test (9/50) with validation entries {208, 210, 48, 213, 111} ...\n",
      "Running Test (10/50) with validation entries {72, 163, 112, 117, 39} ...\n",
      "Running Test (11/50) with validation entries {137, 194, 35, 140, 94} ...\n",
      "Running Test (12/50) with validation entries {26, 211, 140, 190, 154} ...\n",
      "Running Test (13/50) with validation entries {41, 51, 36, 209, 25} ...\n",
      "Running Test (14/50) with validation entries {0, 9, 69, 29, 15} ...\n",
      "Running Test (15/50) with validation entries {212, 138, 195, 76, 63} ...\n",
      "Running Test (16/50) with validation entries {106, 158, 22, 134, 98} ...\n",
      "Running Test (17/50) with validation entries {123, 5, 163, 42, 37} ...\n",
      "Running Test (18/50) with validation entries {37, 51, 131, 197, 79} ...\n",
      "Running Test (19/50) with validation entries {184, 185, 154, 5, 143} ...\n",
      "Running Test (20/50) with validation entries {200, 177, 19, 118, 97} ...\n",
      "Running Test (21/50) with validation entries {216, 81, 161, 209, 89} ...\n",
      "Running Test (22/50) with validation entries {200, 154, 27, 36, 158} ...\n",
      "Running Test (23/50) with validation entries {80, 81, 32, 96, 55} ...\n",
      "Running Test (24/50) with validation entries {201, 98, 125, 94, 33} ...\n",
      "Running Test (25/50) with validation entries {151, 130, 188, 53, 215} ...\n",
      "Running Test (26/50) with validation entries {8, 193, 146, 195, 217} ...\n",
      "Running Test (27/50) with validation entries {88, 99, 156, 5, 199} ...\n",
      "Running Test (28/50) with validation entries {66, 155, 116, 5, 6} ...\n",
      "Running Test (29/50) with validation entries {192, 65, 146, 185, 206} ...\n",
      "Running Test (30/50) with validation entries {207, 82, 179, 164, 15} ...\n",
      "Running Test (31/50) with validation entries {50, 186, 51, 76, 13} ...\n",
      "Running Test (32/50) with validation entries {104, 217, 146, 19, 25} ...\n",
      "Running Test (33/50) with validation entries {0, 91, 59, 148, 87} ...\n",
      "Running Test (34/50) with validation entries {81, 65, 193, 135, 57} ...\n",
      "Running Test (35/50) with validation entries {82, 35, 165, 190, 146} ...\n",
      "Running Test (36/50) with validation entries {41, 178, 171, 118, 55} ...\n",
      "Running Test (37/50) with validation entries {80, 18, 69, 128, 78} ...\n",
      "Running Test (38/50) with validation entries {0, 152, 182, 77, 22} ...\n",
      "Running Test (39/50) with validation entries {72, 138, 147, 100, 130} ...\n",
      "Running Test (40/50) with validation entries {18, 42, 60, 149, 87} ...\n",
      "Running Test (41/50) with validation entries {64, 48, 20, 70, 79} ...\n",
      "Running Test (42/50) with validation entries {56, 34, 84, 20, 86} ...\n",
      "Running Test (43/50) with validation entries {89, 83, 100, 14, 78} ...\n",
      "Running Test (44/50) with validation entries {120, 41, 154, 99, 101} ...\n",
      "Running Test (45/50) with validation entries {27, 84, 181, 38, 127} ...\n",
      "Running Test (46/50) with validation entries {89, 215, 59, 103, 199} ...\n",
      "Running Test (47/50) with validation entries {104, 83, 131, 166, 95} ...\n",
      "Running Test (48/50) with validation entries {89, 210, 52, 190, 127} ...\n",
      "Running Test (49/50) with validation entries {57, 129, 156, 165, 76} ...\n",
      "Running Test (50/50) with validation entries {1, 153, 119, 93, 71} ...\n",
      "Mean prediction error 0.047, Var 0.017, abs.sum 24.865\n"
     ]
    }
   ],
   "source": [
    "print('Cross validate two stage prediction ...')\n",
    "training = parse_dataset('data/new_training_set.xml')\n",
    "cum_errors = cross_validation(50, 5, training, prediction_function=two_stage_prediction, kwargs={'energy_sw': 0.05})\n",
    "print('Mean prediction error %3.3f, Var %3.3f, abs.sum %3.3f' % (cum_errors.mean(), cum_errors.var(), np.sum(np.abs(cum_errors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try with atom_pos and mesh_size_variance\n",
      "Cross validate two stage prediction ...\n",
      "Running Test (1/50) with validation entries {192, 148, 5, 46, 111} ...\n",
      "Running Test (2/50) with validation entries {144, 154, 203, 85, 215} ...\n",
      "Running Test (3/50) with validation entries {193, 130, 215, 97, 41} ...\n",
      "Running Test (4/50) with validation entries {32, 121, 46, 113, 143} ...\n",
      "Running Test (5/50) with validation entries {116, 143, 140, 69, 199} ...\n",
      "Running Test (6/50) with validation entries {48, 103, 111, 197, 183} ...\n",
      "Running Test (7/50) with validation entries {201, 18, 36, 213, 199} ...\n",
      "Running Test (8/50) with validation entries {153, 42, 31, 62, 151} ...\n",
      "Running Test (9/50) with validation entries {48, 76, 109, 62, 127} ...\n",
      "Running Test (10/50) with validation entries {9, 180, 111, 22, 105} ...\n",
      "Running Test (11/50) with validation entries {112, 56, 138, 131, 82} ...\n",
      "Running Test (12/50) with validation entries {217, 172, 109, 182, 86} ...\n",
      "Running Test (13/50) with validation entries {0, 37, 147, 197, 30} ...\n",
      "Running Test (14/50) with validation entries {24, 9, 139, 53, 111} ...\n",
      "Running Test (15/50) with validation entries {59, 26, 35, 172, 86} ...\n",
      "Running Test (16/50) with validation entries {144, 91, 60, 206, 78} ...\n",
      "Running Test (17/50) with validation entries {192, 210, 114, 18, 52} ...\n",
      "Running Test (18/50) with validation entries {98, 195, 180, 181, 7} ...\n",
      "Running Test (19/50) with validation entries {1, 122, 211, 62, 119} ...\n",
      "Running Test (20/50) with validation entries {129, 218, 163, 87, 151} ...\n",
      "Running Test (21/50) with validation entries {184, 170, 163, 92, 206} ...\n",
      "Running Test (22/50) with validation entries {123, 129, 106, 3, 86} ...\n",
      "Running Test (23/50) with validation entries {104, 78, 197, 142, 79} ...\n",
      "Running Test (24/50) with validation entries {48, 99, 146, 27, 95} ...\n",
      "Running Test (25/50) with validation entries {8, 145, 42, 149, 113} ...\n",
      "Running Test (26/50) with validation entries {144, 18, 7, 77, 39} ...\n",
      "Running Test (27/50) with validation entries {25, 114, 51, 100, 46} ...\n",
      "Running Test (28/50) with validation entries {32, 17, 83, 166, 182} ...\n",
      "Running Test (29/50) with validation entries {120, 9, 66, 145, 156} ...\n",
      "Running Test (30/50) with validation entries {216, 65, 186, 180, 173} ...\n",
      "Running Test (31/50) with validation entries {58, 163, 147, 109, 118} ...\n",
      "Running Test (32/50) with validation entries {96, 81, 155, 71, 7} ...\n",
      "Running Test (33/50) with validation entries {128, 89, 115, 96, 55} ...\n",
      "Running Test (34/50) with validation entries {200, 201, 53, 21, 6} ...\n",
      "Running Test (35/50) with validation entries {56, 123, 99, 174, 160} ...\n",
      "Running Test (36/50) with validation entries {88, 33, 134, 78, 167} ...\n",
      "Running Test (37/50) with validation entries {120, 217, 58, 163, 21} ...\n",
      "Running Test (38/50) with validation entries {208, 27, 52, 29, 173} ...\n",
      "Running Test (39/50) with validation entries {38, 121, 20, 113, 23} ...\n",
      "Running Test (40/50) with validation entries {20, 195, 164, 173, 62} ...\n",
      "Running Test (41/50) with validation entries {120, 51, 34, 131, 107} ...\n",
      "Running Test (42/50) with validation entries {24, 73, 42, 53, 110} ...\n",
      "Running Test (43/50) with validation entries {112, 113, 107, 217, 133} ...\n",
      "Running Test (44/50) with validation entries {183, 180, 109, 118, 79} ...\n",
      "Running Test (45/50) with validation entries {96, 194, 92, 77, 52} ...\n",
      "Running Test (46/50) with validation entries {113, 66, 177, 77, 133} ...\n",
      "Running Test (47/50) with validation entries {208, 81, 88, 112, 94} ...\n",
      "Running Test (48/50) with validation entries {128, 88, 139, 133, 35} ...\n",
      "Running Test (49/50) with validation entries {129, 130, 213, 6, 175} ...\n",
      "Running Test (50/50) with validation entries {1, 146, 19, 212, 122} ...\n",
      "Mean prediction error 0.045, Var 0.014, abs.sum 23.216\n"
     ]
    }
   ],
   "source": [
    "print('Try with atom_pos and mesh_size_variance')\n",
    "print('Cross validate two stage prediction ...')\n",
    "training = parse_dataset('data/new_training_set.xml')\n",
    "cum_errors = cross_validation(50, 5, training, prediction_function=two_stage_prediction, kwargs={'energy_sw': 0.05})\n",
    "print('Mean prediction error %3.3f, Var %3.3f, abs.sum %3.3f' % (cum_errors.mean(), cum_errors.var(), np.sum(np.abs(cum_errors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Entry 148 , real energy 0.003\n",
      "Prediction for entry 148: 0.011\n",
      "Closest_ranking entries: [150, 149, 147, 151, 153]\n",
      "Optimal selection [216 138 121 106 107], [ 0.0024  0.0024  0.0035  0.0011  0.0048], mean 0.003\n",
      "Subset based on prediction\n",
      "[ 12  13  14  15  21  26  48  50  51  52  66  67  69  70  80  83 103 105\n",
      " 106 107 108 121 122 123 124 125 136 137 138 139 140 147 149 150 151 152\n",
      " 153 154 160 161 162 163 164 182 186 200 210 211 216]\n"
     ]
    }
   ],
   "source": [
    "e = 3\n",
    "test_entry = entries[e]\n",
    "real_energy = validation[validation['Entry'] == test_entry]['Energy'].values[0]\n",
    "predicted_energy = predictions[e]\n",
    "print('For Entry %d , real energy %3.3f' % (test_entry, real_energy))\n",
    "print('Prediction for entry %d: %3.3f' % (test_entry, predicted_energy))\n",
    "ranking_closest = ranking[test_entry][0:5]\n",
    "ranking_entries = [r[2] for r in ranking_closest]\n",
    "print('Closest_ranking entries: %s' % (ranking_entries))\n",
    "\n",
    "optimal_closest, optimal_energies = get_closest_entries(training, real_energy)\n",
    "print('Optimal selection %s, %s, mean %3.3f' % (optimal_closest[0:5], optimal_energies[0:5], np.mean(optimal_energies[0:5])))\n",
    "\n",
    "# Generate a subset of the entries in trianing based on the prediction\n",
    "utraining = training[['Entry', 'Energy']].drop_duplicates()\n",
    "subset = utraining[(utraining['Energy'] > (predicted_energy-0.1)) & (utraining['Energy'] < (predicted_energy+0.1))]\n",
    "subset_entries = subset['Entry'].values\n",
    "\n",
    "print('Subset based on prediction\\n%s' %(subset_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  12,  13,  14,  15,  21,  24,  25,  26,  27,  32,  48,  50,\n",
       "        51,  52,  55,  67,  69,  70,  78,  80,  82,  83, 103, 104, 105,\n",
       "       106, 107, 108, 110, 119, 121, 122, 123, 124, 125, 128, 134, 136,\n",
       "       137, 138, 139, 140, 143, 144, 147, 149, 150, 151, 152, 153, 154,\n",
       "       160, 161, 162, 163, 164, 171, 172, 175, 180, 182, 185, 186, 200,\n",
       "       210, 211, 212, 216])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def characterise_entry(data_table, entry_ids):\n",
    "    all_characters = []\n",
    "    for entry_id in entry_ids:\n",
    "        characters = {}\n",
    "        pos = get_pos(data_table, entry_id)\n",
    "        \n",
    "        # Calculate the distance matrix\n",
    "        D = cdist(pos, pos, metric='euclidean')\n",
    "        sD = D.copy()\n",
    "        sD.sort(axis=1)\n",
    "        characters['mesh_distance'] = np.mean(sD[:, 1:4])\n",
    "\n",
    "        all_characters.append(characters)\n",
    "    return all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Entry [{'mesh_distance': 2.7128387642113903}]\n",
      "Others\n",
      "[{'mesh_distance': 2.7117290311915774}, {'mesh_distance': 2.7119606322721932}, {'mesh_distance': 2.7078978321662799}, {'mesh_distance': 2.7072373478151017}, {'mesh_distance': 2.6856590599362495}, {'mesh_distance': 2.6871674149923326}, {'mesh_distance': 2.6817326360900502}, {'mesh_distance': 2.7105697782581513}, {'mesh_distance': 2.7048556868771665}, {'mesh_distance': 2.6922581244628501}, {'mesh_distance': 2.6773050147782076}, {'mesh_distance': 2.7138005124619609}, {'mesh_distance': 2.710730224083064}, {'mesh_distance': 2.6805387605221407}, {'mesh_distance': 2.6696537246531111}, {'mesh_distance': 2.6884313049189208}, {'mesh_distance': 2.688479609839082}, {'mesh_distance': 2.7126036022794886}, {'mesh_distance': 2.7139531634814231}, {'mesh_distance': 2.7134423896835314}, {'mesh_distance': 2.7038260299696772}, {'mesh_distance': 2.712251432641402}, {'mesh_distance': 2.7099816414647266}, {'mesh_distance': 2.7084723402079698}, {'mesh_distance': 2.7065735058287488}, {'mesh_distance': 2.7094153030721242}, {'mesh_distance': 2.7137794267850768}, {'mesh_distance': 2.7125455050543286}, {'mesh_distance': 2.709556617936677}, {'mesh_distance': 2.7062782571511859}, {'mesh_distance': 2.7062784739572576}, {'mesh_distance': 2.7117145744313347}, {'mesh_distance': 2.7126554202554694}, {'mesh_distance': 2.7116124352224849}, {'mesh_distance': 2.7084568362104546}, {'mesh_distance': 2.6984312046589469}, {'mesh_distance': 2.7047692096794727}, {'mesh_distance': 2.7006235044932629}, {'mesh_distance': 2.7004024405360041}, {'mesh_distance': 2.7125341726386467}, {'mesh_distance': 2.713018527476605}, {'mesh_distance': 2.7110073962505914}, {'mesh_distance': 2.7085206668529418}, {'mesh_distance': 2.7036425369054151}, {'mesh_distance': 2.7004454735572452}, {'mesh_distance': 2.6917585986406043}, {'mesh_distance': 2.7118859900284664}, {'mesh_distance': 2.7105091901820821}, {'mesh_distance': 2.6897152965984015}]\n"
     ]
    }
   ],
   "source": [
    "test_char = characterise_entry(validation, [test_entry])\n",
    "rest_char = characterise_entry(training, subset_entries)\n",
    "\n",
    "print('Test Entry %s' % (test_char))\n",
    "print('Others\\n%s' % rest_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.25556265,  2.04974858,  2.54751913,  2.49542602,  3.99036079,\n",
       "        4.35478608,  3.58938472,  4.78022724,  3.55014216,  4.3378977 ,\n",
       "        4.40292995,  5.19201513,  2.79106657,  3.78204809,  5.64012917,\n",
       "        4.79728601,  4.95482542,  3.59118626,  5.75552764,  4.43885973,\n",
       "        6.31293727,  5.7700784 ,  6.271003  ,  4.47857438,  4.51784364,\n",
       "        3.6139715 ,  4.07431902,  5.17409053,  4.51534389,  4.30386145,\n",
       "        4.90205037,  5.87167186,  6.72958229,  6.31079537,  5.52663515,\n",
       "        5.63885774,  5.90172222,  6.93463571,  6.42064926,  5.94772687,\n",
       "        4.39828149,  7.00167225,  6.74585549,  7.23314105,  4.84333516,\n",
       "        4.51691913,  6.72191267,  6.26962099,  6.75865645,  4.99732055,\n",
       "        5.79332566,  7.28647164,  6.67763817,  4.3346693 ,  5.4211885 ,\n",
       "        6.37946002,  4.79224952,  5.15842198,  6.39650756,  5.74993117])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = get_pos(training, 0)\n",
    "D = cdist(pos, pos, metric='euclidean')\n",
    "sD = D.copy()\n",
    "sD.sort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9999999999998243e-05"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_distance = [c['mesh_distance'] for c in rest_char]\n",
    "closest = subset_entries[np.argsort(mesh_distance)]\n",
    "\n",
    "np.mean(get_energies(training, closest[0:3]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
